{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import所需要的元件\n",
    "request:用來取得html檔案\n",
    "time:延遲時間\n",
    "os:建立資料夾\n",
    "BeautifulSoup:可解析html檔案 利用標籤選擇器篩選資料\n",
    "以下網址有關於BeautifulSoup的教學參考\n",
    "https://www.youtube.com/watch?v=yG8-mKyLmNw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import os\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由於原網址清空BOX了暫時抓不到"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listurl='https://www.knbsb.nl/competitie/competities/honkbal-competities/!/uitslagen/H100/honkbal-hoofdklasse/reguliere-competitie'\n",
    "res = requests.get(listurl)\n",
    "soup1 = BeautifulSoup(res.text,'lxml')\n",
    "ops = soup1.find_all('option')\n",
    "for op in ops:\n",
    "    listurl='https://www.knbsb.nl/competitie/competities/honkbal-competities/!/uitslagen/'+op['value']\n",
    "    folder = op['value'].split('/')[2]\n",
    "    print(folder)\n",
    "    try:\n",
    "        os.mkdir(folder)\n",
    "    except IOError:\n",
    "        print(\"Error: folder already exixt\")\n",
    "    res = requests.get(listurl);\n",
    "    soup2 = BeautifulSoup(res.text,'lxml')\n",
    "    boxes=soup2.find_all(attrs={'class':'icon'})\n",
    "    for box in boxes:\n",
    "        url=box.a['href']\n",
    "        res = requests.get(url)\n",
    "        soup = BeautifulSoup(res.text,'lxml')\n",
    "        print(soup.title.string)\n",
    "        print(soup.find_all(attrs={'size':'3'})[1].text.split('\\n')[2]+'\\n')\n",
    "        logs=soup.find_all(attrs={'cellpadding':'3'})\n",
    "        \n",
    "        try:\n",
    "            fo = open(os.getcwd()+\"\\\\\"+folder+\"\\\\\"+soup.title.string+\".txt\", \"w\")\n",
    "        except IOError:\n",
    "            print(\"Error: cannot open file\")\n",
    "\n",
    "        for log in logs:\n",
    "            print(log.b.text.replace(\" -\",''))\n",
    "            print(log.text.replace(log.b.text,'').replace(log.i.text,'').strip().replace('\\n',' ').replace(\". \",\".\\n\").replace(\"; \",\";\\n\"))\n",
    "            print(log.i.text.replace('\\n',' ')+'\\n')\n",
    "            fo.write(log.b.text.replace(\" -\",'')+'\\n');\n",
    "            fo.write(log.text.replace(log.b.text,'').replace(log.i.text,'').strip().replace('\\n',' ').replace(\". \",\".\\n\").replace(\"; \",\";\\n\")+'\\n')\n",
    "            fo.write(log.i.text.replace('\\n',' ')+'\\n')\n",
    "        fo.write(soup.find_all(attrs={'size':'3'})[1].text.split('\\n')[2]+'\\n')\n",
    "        fo.close()\n",
    "        time.sleep(0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由庫存網頁抓取過去的比賽資料網址\n",
    "\n",
    "find_all:將所有符合條件的資料依照順序做成一個List檔案\n",
    "attrs={'class':'icon'} :篩選條件attribute為class='icon'的網址資料\n",
    "再由迴圈將url印出確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listurl='https://webcache.googleusercontent.com/search?q=cache:Mjmq83yWFgYJ:https://www.knbsb.nl/competitie/competities/honkbal-competities/!/uitslagen/H100/honkbal-hoofdklasse/reguliere-competitie+&cd=1&hl=zh-TW&ct=clnk&gl=tw'\n",
    "res = requests.get(listurl);\n",
    "soup = BeautifulSoup(res.text,'lxml')\n",
    "boxes=soup.find_all(attrs={'class':'icon'})\n",
    "for box in boxes:\n",
    "        url=box.a['href']\n",
    "        print(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由上面抓到的網址List來將每個比賽的play by play抓下來\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for box in boxes:\n",
    "    url=box.a['href']\n",
    "    res = requests.get(url)\n",
    "    soup = BeautifulSoup(res.text,'lxml')\n",
    "\n",
    "    print(soup.title.string))             #比賽標題包含隊伍和日期\n",
    "    print(soup.find_all(attrs={'size':'3'})[1].text.split('\\n')[2]+'\\n')  #雙方比分\n",
    "    logs=soup.find_all(attrs={'cellpadding':'3'})   #playbyplay list\n",
    "\n",
    "    try:\n",
    "       os.mkdir(\"reguliere-competitie\")          #建立該賽季資料夾\n",
    "    except IOError:\n",
    "        print(\"Error: folder already exixt\") \n",
    "\n",
    "    fo = open(os.getcwd()+\"\\\\reguliere-competitie\\\\\"+soup.title.string+\".txt\", \"w\") #以標題作為檔名\n",
    "    \n",
    "    for log in logs:\n",
    "        print(log.b.text.replace(\" -\",''))   #b標籤為某隊伍第幾局 去掉後面多餘的部分\n",
    "        #底下為playlog 將b標籤和i標籤的資料用replace去除掉 strip用來去掉換行空格 接著再用replace整理句子\n",
    "        print(log.text.replace(log.b.text,'').replace(log.i.text,'').strip().replace('\\n',' ').replace(\". \",\".\\n\").replace(\"; \",\";\\n\"))\n",
    "        print(log.i.text.replace('\\n',' ')+'\\n')#i標籤為該局的結果\n",
    "        #底下將資料寫入檔案\n",
    "        fo.write(log.b.text.replace(\" -\",'')+'\\n');\n",
    "        fo.write(log.text.replace(log.b.text,'').replace(log.i.text,'').strip().replace('\\n',' ').replace(\". \",\".\\n\").replace(\"; \",\";\\n\")+'\\n')\n",
    "        fo.write(log.i.text.replace('\\n',' ')+'\\n')\n",
    "    fo.write(soup.find_all(attrs={'size':'3'})[1].text.split('\\n')[2]+'\\n')  #於最後寫入隊伍比分\n",
    "    fo.close()    #關檔 換下一場比賽\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
